# Task 6: K-Nearest Neighbors (KNN) Classification â€“ Iris Dataset

## ğŸ¯ Objective
Implement and evaluate the K-Nearest Neighbors (KNN) algorithm on a classification dataset. Experiment with different K values, evaluate accuracy, and visualize decision boundaries.

---

## ğŸ“ Files Included
- `knn_classifier.py` â€“ Main KNN code
- `iris.csv` â€“ Dataset from Kaggle or scikit-learn
- `knn_accuracy_plot.png` â€“ Accuracy vs K plot
- `README.md` â€“ This documentation

---

## ğŸ› ï¸ Libraries Used
- pandas
- numpy
- matplotlib
- seaborn
- scikit-learn

---

## ğŸ” Steps Performed
1. Loaded the Iris dataset.
2. Normalized features using `StandardScaler`.
3. Split data into train/test sets.
4. Trained **KNeighborsClassifier** with multiple values of **K**.
5. Evaluated performance using **accuracy** and **confusion matrix**.
6. Visualized **accuracy vs K** and decision boundary.

---

## ğŸ–¼ï¸ Visuals

### ğŸ”¹ KNN Accuracy Plot
![KNN Accuracy Plot](knn_accuracy_plot.png)